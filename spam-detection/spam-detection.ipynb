{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Application: Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SPAM can be defined as massive, undesired e-mail communications that are sent to large numbers of people\n",
    "without their authorization. While the contents vary from one case to another, it has been\n",
    "observed that the main topics of these mails are pharmacy products, gambling, weight loss,\n",
    "and phishing attempts.\n",
    "\n",
    "It is important to note that SPAM is not only annoying but also expensive. Today, many\n",
    "people check their inboxes using a cell-phone data plan. Every e-mail requires an amount of\n",
    "data transfer, which the client must pay for. Additionally, SPAM costs money for Internet\n",
    "Service Providers (ISPs) as it is transmitted through their servers and other network\n",
    "devices. Once we have considered this aspect of SPAM, we will want to avoid it to the\n",
    "maximum extent possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the dataset and print the total number of lines,each representing a record.\n",
    "`rstrip()` Python method is used to strip whitespace characters from the end of each line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5574"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset 'SMSSpamCollection' into variable 'messages'\n",
    "messages = [line.rstrip() for line in open('sms-data/SMSSpamCollection')]\n",
    "# Print number of messages\n",
    "len(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the messages by parsing the dataset file using pandas. The use of the `head()` method causes pandas to return only the first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset. Specify the field separator is a tab instead of a comma.\n",
    "# Additionally, add column captions ('label' and 'message') for the two fields in the dataset.\n",
    "# To preserve internal quotations in messages, use QUOTE_NONE.\n",
    "messages = pd.read_csv('sms-data/SMSSpamCollection', sep='\\t',quoting=csv.QUOTE_NONE,names=[\"class\", \"message\"])\n",
    "# Print first 5 records\n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first column has been labeled class, whereas the second column is message. In class, we can see the\n",
    "individual classification of each message as ham (good) or spam (bad):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `groupby()` and `count()` methods to group the records by class and then count the number in each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       message\n",
       "class         \n",
       "ham       4827\n",
       "spam       747"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by class and count\n",
    "messages.groupby('class').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bag-of-words model\n",
    "This is a common document classification technique where the occurrence and\n",
    "the frequency of each word is used to train a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split each message into a series of words\n",
    "def split_into_words(message):\n",
    "    return TextBlob(message).words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [Go, until, jurong, point, crazy, Available, o...\n",
       "1                       [Ok, lar, Joking, wif, u, oni]\n",
       "2    [Free, entry, in, 2, a, wkly, comp, to, win, F...\n",
       "3    [U, dun, say, so, early, hor, U, c, already, t...\n",
       "4    [Nah, I, do, n't, think, he, goes, to, usf, he...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what the first 5 records look when splitted into individual words\n",
    "messages.message.head().apply(split_into_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Normalize the words into their base form and convert each message into a vector to train the model. \n",
    "In this step, words such as walking,walked, walks, and walk are reduced into their lemmaâ€“walk. Thus, the presence of\n",
    "any of those words will actually count toward the number of occurrences of walk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each word into its base form\n",
    "def words_into_base_form(message):\n",
    "    message = message.lower()\n",
    "    words = TextBlob(message).words\n",
    "    return [word.lemma for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each message into a vector\n",
    "training_vector = CountVectorizer(analyzer=words_into_base_form).fit(messages['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x8859 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View occurrence of words in an arbitrary vector. Use 19 for vector #20.\n",
    "message20 = training_vector.transform([messages['message'][19]])\n",
    "message20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
      "First word that appears twice: free2day\n",
      "Word that appears three times: model..sony\n"
     ]
    }
   ],
   "source": [
    "# Print message #10 for comparison\n",
    "print (messages['message'][9])\n",
    "# Identify repeated words\n",
    "print ('First word that appears twice:',training_vector.get_feature_names()[3437])\n",
    "print ('Word that appears three times:',training_vector.get_feature_names()[5192])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term frequency (TF, the number of times a term occurs in a document) and inverse document frequency (IDF) of each word. The IDF diminishes the weight of a word that appears very frequently and increases the weight of words that do not occur often:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bag-of-words for the entire training dataset\n",
    "messagesBagOfWords = training_vector.transform(messages['message'])\n",
    "# Weight of words in the entire training dataset -Term Frequency and Inverse Document Frequency\n",
    "messagesTfidf = TfidfTransformer().fit(messagesBagOfWords).transform(messagesBagOfWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on these preceding statistical values, we will be able to train our modelusing the **Naive-Bayes algorithm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "spamDetector = MultinomialNB().fit(messagesTfidf,messages['class'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You have trained your model to perform SPAM detection. Now we'll test it against new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message [ Thanks for your Ringtone Order, Reference T91. You will be charged GBP 4 per week. You can unsubscribe at anytime by calling customer services on 09057039994 ] has been classified as spam\n"
     ]
    }
   ],
   "source": [
    "# Test message\n",
    "example = [\"Thanks for your Ringtone Order, Reference T91. You will be charged GBP 4 per week. You can unsubscribe at anytime by calling customer services on 09057039994\"]\n",
    "# Result\n",
    "checkResult = spamDetector.predict(training_vector.transform(example))[0]\n",
    "print ('The message [',example[0],'] has been classified as', checkResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The message [ Can you say what happen ] has been classified as ham\n"
     ]
    }
   ],
   "source": [
    "# Test message\n",
    "example = [\"Can you say what happen\"]\n",
    "# Result\n",
    "checkResult = spamDetector.predict(training_vector.transform(example))[0]\n",
    "print ('The message [',example[0],'] has been classified as', checkResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have tested our model successfully with two test messages. Feel free to experiment with your own messages now."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
